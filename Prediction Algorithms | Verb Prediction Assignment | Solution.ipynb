{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Prediction Algorithms | Verb Prediction | Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T06:52:12.198070Z",
     "start_time": "2019-02-17T06:52:12.191109Z"
    }
   },
   "source": [
    "***Please find the assignments to submit following the sample code.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "This notebook contains working code as the basis for your assignment. It fetches and loads the necessary data you will work on during this assignment, and demonstrates all the initial steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Prerequisites\n",
    "+ **Python 3.6.x.** You may install python via the [Anaconda distribution](https://www.anaconda.com/distribution/#download-section) which will also automatically install many useful python libraries, but this is not mandatory. To import a library in a notebook or python file, it must first be _installed_; this is a prerequisite to running this notebook. Anaconda will out-of-the-box install most/all of the libraries which are imported by this notebook. The latest version of Anaconda comes with python 3.7, so you will have to dig for the previous version of Anaconda.\n",
    "<br><Br>\n",
    "+ Python packages used in this notebook should be installed. <br><br>\n",
    "    + To install any missing or helpful python packages with Anaconda, you would typically issue the following command given below. This command assumes that the package you are after has been made publically available on the official Anaconda distribution channel (called conda-forge). The `conda` command is Anaconda's setup tool that comes along with the Anaconda distribution. If you installed Anaconda, you should have this command available in your command prompt.\n",
    "```\n",
    "conda install -c conda-forge <package name>\n",
    "```\n",
    "    + Further setup notes:\n",
    "         + When run, the `conda install` command may take a while to resolve all dependencies.\n",
    "         + Some packages are not available through Anaconda, in which case use the famous pip utility to install the missing package/s into your python environment.\n",
    "         + You are entirely free to install python and the necessary packages in other ways\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Getting Started with this notebook\n",
    "+ Follow the cells and their outputs to confirm you understand what they are doing. \n",
    "+ Use it as a learning opportunity about idiomatic python, if you are relatively new to python!\n",
    "+ Make a local copy of the notebook ― <br>and make sure it is running on your machine, with outpus similar to those already appearing in this pre-run copy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:58:53.059457Z",
     "start_time": "2019-02-21T04:58:52.532457Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook, trange # progress bars\n",
    "import pyconll # library parsing CoNLL-U files\n",
    "from pprint import pprint # slightly nicer printing of data structures\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import itertools \n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T08:05:18.965894Z",
     "start_time": "2019-02-11T08:05:18.957234Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Downloading and loading the HTB corpus\n",
    "To future-proof, we standardize on a specific version of the HTB. <br>Those with a keen eye will notice we use here the quick-and-dirty ⚡ way of launching OS commands from directly within the notebook. <br>⚙ Anyway, make sure you have git installed and working on your OS before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:58:53.071042Z",
     "start_time": "2019-02-21T04:58:53.061099Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "!git clone https://github.com/UniversalDependencies/UD_Hebrew-HTB\n",
    "!cd UD_Hebrew-HTB && git checkout 82591c955e86222e32531336ff23e36c220b5846"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:58:56.247242Z",
     "start_time": "2019-02-21T04:58:53.073936Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "conllu1 = pyconll.load_from_file('UD_Hebrew-HTB/he_htb-ud-dev.conllu')\n",
    "conllu2 = pyconll.load_from_file('UD_Hebrew-HTB/he_htb-ud-test.conllu')\n",
    "conllu3 = pyconll.load_from_file('UD_Hebrew-HTB/he_htb-ud-train.conllu')\n",
    "\n",
    "conllu = [conllu1, conllu2, conllu3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick data exploration\n",
    "lets quantify how many verbs do we have per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:58:56.363207Z",
     "start_time": "2019-02-21T04:58:56.250038Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "counts = []\n",
    "for sentence in itertools.chain(*conllu): # the asterisk unpacks the array into an argument list\n",
    "    verbs = 0\n",
    "    for token in sentence:\n",
    "        if token.upos == 'VERB':\n",
    "            verbs += 1 #print(token.form)\n",
    "    counts.append(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:58:56.684399Z",
     "start_time": "2019-02-21T04:58:56.365771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      511\n",
       "1     1673\n",
       "2     1748\n",
       "3     1099\n",
       "4      604\n",
       "5      321\n",
       "6      140\n",
       "7       66\n",
       "8       26\n",
       "9       15\n",
       "10       6\n",
       "11       3\n",
       "12       3\n",
       "15       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "counts = pd.Series(counts)\n",
    "counts.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:58:56.934623Z",
     "start_time": "2019-02-21T04:58:56.685802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,528 unique verbs in training data\n",
      "28,205 unique non-verbs in training data\n",
      "632 words are ambiguous\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verbs = {}\n",
    "non_verbs = {}\n",
    "\n",
    "for sentence in itertools.chain(*conllu):\n",
    "    for token in sentence:\n",
    "        if token.upos == 'VERB':\n",
    "            if token.form in verbs:\n",
    "                verbs.update({token.form : verbs[token.form]+1})\n",
    "            else:\n",
    "                verbs.update({token.form : 0})\n",
    "        else:\n",
    "            if token.form in non_verbs:\n",
    "                non_verbs.update({token.form : non_verbs[token.form]+1})\n",
    "            else:\n",
    "                non_verbs.update({token.form : 0})\n",
    "\n",
    "    \n",
    "print('{:,} unique verbs in training data'.format(len(verbs)))\n",
    "print('{:,} unique non-verbs in training data'.format(len(non_verbs)))\n",
    "\n",
    "ambiguous = set(verbs.keys()) & set(non_verbs.keys())\n",
    "\n",
    "print('{:,} words are ambiguous'.format(len(ambiguous)))\n",
    "print()\n",
    "#print('ambiguous words:\\n' + str(ambiguous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:58:56.947251Z",
     "start_time": "2019-02-21T04:58:56.936535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after removing ambiguous words:\n",
      "\n",
      "4,896 unique verbs in training data\n",
      "27,573 unique non-verbs in training data\n"
     ]
    }
   ],
   "source": [
    "verbs     = {k:v for (k,v) in verbs.items() if not k in ambiguous} # this is called a dict comprehension\n",
    "non_verbs = {k:v for (k,v) in non_verbs.items() if not k in ambiguous}\n",
    "\n",
    "print('after removing ambiguous words:\\n')\n",
    "print('{:,} unique verbs in training data'.format(len(verbs)))\n",
    "print('{:,} unique non-verbs in training data'.format(len(non_verbs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proportion of verbs in the overall lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:58:57.011176Z",
     "start_time": "2019-02-21T04:58:56.948833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15078998429270998"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(verbs) / (len(verbs) + len(non_verbs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building a histogram of the ngrams and their occurences, for ngrams up to length 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:58:57.215520Z",
     "start_time": "2019-02-21T04:58:57.013003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3ba197922142f0b1fb95f1cdb51836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32469), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ngrams = dict()\n",
    "max_ngram_len = 2\n",
    "\n",
    "lexicon = list(verbs.keys()) + list(non_verbs.keys())\n",
    "\n",
    "# for each verb \n",
    "for verb in tqdm_notebook(lexicon): # tqdm is just a nice utility for getting a progress bar for a long loop\n",
    "    # per ngram length\n",
    "    for ngram_len in range(1,max_ngram_len): \n",
    "        # sliding window iterate its ngrams\n",
    "        for idx in range(len(verb) - ngram_len + 1):\n",
    "            ngram = verb[idx : idx + 2] \n",
    "\n",
    "            if ngram in ngrams:\n",
    "                ngrams[ngram] += 1\n",
    "            else:\n",
    "                ngrams[ngram] = 0        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:58:57.222186Z",
     "start_time": "2019-02-21T04:58:57.217331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921 ngrams extracted from the corpus\n",
      "873 2-grams\n",
      "48 1-grams\n",
      "\n",
      "['!', '\"', '\"א', '\"ב', '\"ג', '\"ד', '\"ה', '\"ו', '\"ז', '\"ח', '\"ט', '\"י', '\"ך', '\"כ', '\"ל', '\"ם', '\"מ', '\"ן', '\"נ', '\"ס', '\"ע', '\"ף', '\"פ', '\"ץ', '\"צ', '\"ק', '\"ר', '\"ש', '\"ת', '%', '(', ')', ',', ',0', ',1', ',2', ',3', ',4', ',5', ',6', ',7', ',8', ',9', '-', '.', '..', '.0', '.1', '.2', '.3', '.4', '.5', '.6', '.7', '.8', '.9', '.א', '.ב', '.ד', '.כ', '.ס', '.פ', '.ר', '0', '0,', '0.', '00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '1', '1,', '1.', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '1פ', '2', '2,', '2.', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '2ח', '2ש', '3', '3,', '3.', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '4,', '4.', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '5,', '5.', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '6,', '6.', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '6א', '7', '7,', '7.', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '8.', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '9,', '9.', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '9:', ':', ':0', ';', '?', '_', '__', '_א', '_ה', '_ש', 'א', 'א\"', 'א.', 'א_', 'אא', 'אב', 'אג', 'אד', 'אה', 'או', 'אז', 'אח', 'אט', 'אי', 'אך', 'אכ', 'אל', 'אם', 'אמ', 'אן', 'אנ', 'אס', 'אע', 'אף', 'אפ', 'אץ', 'אצ', 'אק', 'אר', 'אש', 'את', 'ב', 'ב\"', 'ב0', 'ב1', 'ב2', 'ב3', 'ב4', 'ב5', 'ב6', 'ב7', 'ב8', 'ב9', 'ב_', 'בא', 'בב', 'בג', 'בד', 'בה', 'בו', 'בז', 'בח', 'בט', 'בי', 'בך', 'בכ', 'בל', 'בם', 'במ', 'בן', 'בנ', 'בס', 'בע', 'בפ', 'בץ', 'בצ', 'בק', 'בר', 'בש', 'בת', 'ג', 'ג\"', 'ג.', 'ג_', 'גא', 'גב', 'גג', 'גד', 'גה', 'גו', 'גז', 'גח', 'גט', 'גי', 'גל', 'גם', 'גמ', 'גן', 'גנ', 'גס', 'גע', 'גף', 'גפ', 'גק', 'גר', 'גש', 'גת', 'ד', 'ד\"', 'ד.', 'ד_', 'דא', 'דב', 'דג', 'דד', 'דה', 'דו', 'דז', 'דח', 'דט', 'די', 'דך', 'דכ', 'דל', 'דם', 'דמ', 'דן', 'דנ', 'דס', 'דע', 'דף', 'דפ', 'דצ', 'דק', 'דר', 'דש', 'דת', 'ה', 'ה\"', 'ה0', 'ה1', 'ה2', 'ה3', 'ה4', 'ה5', 'ה6', 'ה7', 'ה8', 'ה9', 'ה_', 'הא', 'הב', 'הג', 'הד', 'הה', 'הו', 'הז', 'הח', 'הט', 'הי', 'הכ', 'הל', 'הם', 'המ', 'הן', 'הנ', 'הס', 'הע', 'הפ', 'הצ', 'הק', 'הר', 'הש', 'הת', 'ו', 'ו\"', 'ו.', 'ו0', 'ו1', 'ו2', 'ו3', 'ו4', 'ו5', 'ו6', 'ו7', 'ו8', 'ו_', 'וא', 'וב', 'וג', 'וד', 'וה', 'וו', 'וז', 'וח', 'וט', 'וי', 'וך', 'וכ', 'ול', 'ום', 'ומ', 'ון', 'ונ', 'וס', 'וע', 'וף', 'ופ', 'וץ', 'וצ', 'וק', 'ור', 'וש', 'ות', 'ז', 'ז\"', 'ז_', 'זא', 'זב', 'זג', 'זד', 'זה', 'זו', 'זז', 'זח', 'זט', 'זי', 'זכ', 'זל', 'זם', 'זמ', 'זן', 'זנ', 'זע', 'זף', 'זפ', 'זצ', 'זק', 'זר', 'זת', 'ח', 'ח\"', 'ח.', 'ח2', 'ח_', 'חא', 'חב', 'חג', 'חד', 'חה', 'חו', 'חז', 'חח', 'חט', 'חי', 'חכ', 'חל', 'חם', 'חמ', 'חן', 'חנ', 'חס', 'חף', 'חפ', 'חץ', 'חצ', 'חק', 'חר', 'חש', 'חת', 'ט', 'ט\"', 'ט.', 'ט_', 'טא', 'טב', 'טג', 'טד', 'טה', 'טו', 'טז', 'טח', 'טט', 'טי', 'טכ', 'טל', 'טם', 'טמ', 'טן', 'טנ', 'טס', 'טע', 'טף', 'טפ', 'טצ', 'טק', 'טר', 'טש', 'טת', 'י', 'י\"', 'י.', 'י5', 'י_', 'יא', 'יב', 'יג', 'יד', 'יה', 'יו', 'יז', 'יח', 'יט', 'יי', 'יך', 'יכ', 'יל', 'ים', 'ימ', 'ין', 'ינ', 'יס', 'יע', 'יף', 'יפ', 'יץ', 'יצ', 'יק', 'יר', 'יש', 'ית', 'ך', 'ך_', 'כ', 'כ\"', 'כ.', 'כ0', 'כ1', 'כ2', 'כ3', 'כ4', 'כ5', 'כ6', 'כ7', 'כ9', 'כא', 'כב', 'כג', 'כד', 'כה', 'כו', 'כז', 'כח', 'כט', 'כי', 'כך', 'ככ', 'כל', 'כם', 'כמ', 'כן', 'כנ', 'כס', 'כע', 'כף', 'כפ', 'כץ', 'כצ', 'כק', 'כר', 'כש', 'כת', 'ל', 'ל\"', 'ל.', 'ל0', 'ל1', 'ל2', 'ל3', 'ל4', 'ל5', 'ל6', 'ל7', 'ל8', 'ל9', 'ל_', 'לא', 'לב', 'לג', 'לד', 'לה', 'לו', 'לז', 'לח', 'לט', 'לי', 'לך', 'לכ', 'לל', 'לם', 'למ', 'לן', 'לנ', 'לס', 'לע', 'לף', 'לפ', 'לץ', 'לצ', 'לק', 'לר', 'לש', 'לת', 'ם', 'ם_', 'מ', 'מ\"', 'מ0', 'מ1', 'מ2', 'מ3', 'מ5', 'מ6', 'מ7', 'מ8', 'מא', 'מב', 'מג', 'מד', 'מה', 'מו', 'מז', 'מח', 'מט', 'מי', 'מך', 'מכ', 'מל', 'מם', 'ממ', 'מן', 'מנ', 'מס', 'מע', 'מף', 'מפ', 'מץ', 'מצ', 'מק', 'מר', 'מש', 'מת', 'ן', 'ן_', 'נ', 'נ\"', 'נ.', 'נא', 'נב', 'נג', 'נד', 'נה', 'נו', 'נז', 'נח', 'נט', 'ני', 'נך', 'נכ', 'נל', 'נם', 'נמ', 'נן', 'ננ', 'נס', 'נע', 'נף', 'נפ', 'נץ', 'נצ', 'נק', 'נר', 'נש', 'נת', 'ס', 'ס\"', 'ס.', 'ס_', 'סא', 'סב', 'סג', 'סד', 'סה', 'סו', 'סח', 'סט', 'סי', 'סך', 'סכ', 'סל', 'סם', 'סמ', 'סן', 'סנ', 'סס', 'סע', 'סף', 'ספ', 'סצ', 'סק', 'סר', 'סת', 'ע', 'ע\"', 'ע_', 'עא', 'עב', 'עג', 'עד', 'עה', 'עו', 'עז', 'עט', 'עי', 'עך', 'עכ', 'על', 'עם', 'עמ', 'ען', 'ענ', 'עס', 'עע', 'עף', 'עפ', 'עץ', 'עצ', 'עק', 'ער', 'עש', 'עת', 'ף', 'ף_', 'פ', 'פ\"', 'פ.', 'פ6', 'פא', 'פב', 'פג', 'פד', 'פה', 'פו', 'פז', 'פח', 'פט', 'פי', 'פך', 'פכ', 'פל', 'פם', 'פמ', 'פן', 'פנ', 'פס', 'פע', 'פף', 'פפ', 'פץ', 'פצ', 'פק', 'פר', 'פש', 'פת', 'ץ', 'ץ_', 'צ\"', 'צ.', 'צא', 'צב', 'צג', 'צד', 'צה', 'צו', 'צז', 'צח', 'צט', 'צי', 'צכ', 'צל', 'צם', 'צמ', 'צן', 'צנ', 'צס', 'צע', 'צף', 'צפ', 'צץ', 'צצ', 'צק', 'צר', 'צת', 'ק', 'ק\"', 'ק.', 'ק_', 'קא', 'קב', 'קג', 'קד', 'קה', 'קו', 'קז', 'קח', 'קט', 'קי', 'קל', 'קם', 'קמ', 'קן', 'קנ', 'קס', 'קע', 'קף', 'קפ', 'קץ', 'קצ', 'קק', 'קר', 'קש', 'קת', 'ר', 'ר\"', 'ר.', 'ר_', 'רא', 'רב', 'רג', 'רד', 'רה', 'רו', 'רז', 'רח', 'רט', 'רי', 'רך', 'רכ', 'רל', 'רם', 'רמ', 'רן', 'רנ', 'רס', 'רע', 'רף', 'רפ', 'רץ', 'רצ', 'רק', 'רר', 'רש', 'רת', 'ש', 'ש\"', 'ש.', 'ש2', 'ש_', 'שא', 'שב', 'שג', 'שד', 'שה', 'שו', 'שז', 'שח', 'שט', 'שי', 'שך', 'שכ', 'של', 'שם', 'שמ', 'שן', 'שנ', 'שס', 'שע', 'שף', 'שפ', 'שצ', 'שק', 'שר', 'שש', 'שת', 'ת', 'ת\"', 'ת.', 'ת2', 'ת_', 'תא', 'תב', 'תג', 'תד', 'תה', 'תו', 'תז', 'תח', 'תט', 'תי', 'תך', 'תכ', 'תל', 'תם', 'תמ', 'תן', 'תנ', 'תס', 'תע', 'תף', 'תפ', 'תצ', 'תק', 'תר', 'תש', 'תת']\n"
     ]
    }
   ],
   "source": [
    "print('{} ngrams extracted from the corpus'.format(len(ngrams)))\n",
    "_1grams = list(filter(lambda ngram: len(ngram) == 1, ngrams))\n",
    "_2grams = list(filter(lambda ngram: len(ngram) == 2, ngrams))\n",
    "print('{} 2-grams'.format(len(_2grams)))\n",
    "print('{} 1-grams'.format(len(_1grams)))\n",
    "print()\n",
    "print(str(sorted(ngrams.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T05:43:44.877408Z",
     "start_time": "2019-02-17T05:43:44.872621Z"
    },
    "hideOutput": true
   },
   "source": [
    "## Getting down to business\n",
    "In the following we test whether ngrams are enough for classifying words into verbs v.s. non-verbs. This demonstrates the entire flow of classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:58:57.319682Z",
     "start_time": "2019-02-21T04:58:57.223834Z"
    }
   },
   "outputs": [],
   "source": [
    "# a mapping from feature vector index to feature description ― must be kept aligned to the vectorize function!\n",
    "\n",
    "feature_vector_description = \\\n",
    "    [(ngram, 'occurs') for ngram in enumerate(ngrams)] + \\\n",
    "    [(ngram, 'startswith') for ngram in enumerate(ngrams)] + \\\n",
    "    [(ngram, 'endswith') for ngram in enumerate(ngrams)]\n",
    "\n",
    "def feature_to_description(idx):\n",
    "    return feature_vector_description[idx]\n",
    "\n",
    "def vectorize(word):\n",
    "    ''' turn the given word into a feature vector '''\n",
    "    \n",
    "    # ngram occurences\n",
    "    vec1 = [0] * len(ngrams)\n",
    "    for idx, ngram in enumerate(ngrams):\n",
    "        if ngram in word:\n",
    "            vec1[idx] = 1\n",
    "            \n",
    "    # ngram occurences as prefix\n",
    "    vec2 = [0] * len(ngrams)\n",
    "    for idx, ngram in enumerate(ngrams):\n",
    "        if word.startswith(ngram):\n",
    "            vec2[idx] = 1\n",
    "\n",
    "    # ngram occurences as suffix\n",
    "    vec3 = [0] * len(ngrams)\n",
    "    for idx, ngram in enumerate(ngrams):\n",
    "        if word.endswith(ngram):\n",
    "            vec3[idx] = 1\n",
    "        \n",
    "    return vec1 + vec2 + vec3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:58:57.393078Z",
     "start_time": "2019-02-21T04:58:57.321747Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, train_proportion=0.8):\n",
    "    ''' split the given data into train and test sets '''\n",
    "\n",
    "    assert len(X) == len(y), 'input data should have exactly one prediction per input'\n",
    "    assert 0 < train_proportion < 1, 'this function requires a proportion between zero and one as its second argument'\n",
    "    \n",
    "    data_indices = set(range(len(X)))\n",
    "    data_count = len(data_indices)\n",
    "\n",
    "    train_indices = set(random.sample(data_indices, int(data_count * train_proportion)))\n",
    "    test_indices  = data_indices - train_indices\n",
    "    \n",
    "    X_train = [X[idx] for idx in train_indices]\n",
    "    X_test  = [X[idx] for idx in test_indices]\n",
    "    \n",
    "    y_train = [y[idx] for idx in train_indices]\n",
    "    y_test  = [y[idx] for idx in test_indices]\n",
    "\n",
    "    assert len(X_train) + len(X_test) == len(X)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:59:08.658003Z",
     "start_time": "2019-02-21T04:58:57.395990Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_positive = list(map(vectorize, verbs.keys()))\n",
    "X_negative = list(map(vectorize, non_verbs.keys()))\n",
    "\n",
    "y_positive = [1] * len(X_positive)\n",
    "y_negative = [0] * len(X_negative)\n",
    "\n",
    "X_train_pos, X_test_pos, y_train_pos, y_test_pos = train_test_split(X_positive, y_positive)\n",
    "X_train_neg, X_test_neg, y_train_neg, y_test_neg = train_test_split(X_negative, y_negative)\n",
    "\n",
    "X_train = X_train_pos + X_train_neg\n",
    "y_train = y_train_pos + y_train_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:59:08.663038Z",
     "start_time": "2019-02-21T04:59:08.659787Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_sample_weight = 1\n",
    "neg_sample_weight = 1\n",
    "sample_weights = ([pos_sample_weight] * len(X_train_pos)) + ([neg_sample_weight] * len(X_train_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:59:12.493480Z",
     "start_time": "2019-02-21T04:59:08.664485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "#clf = LogisticRegression()\n",
    "\n",
    "clf.fit(X_train, y_train, sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:59:12.508550Z",
     "start_time": "2019-02-21T04:59:12.495082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-10.86988187137653, ((298, 'ככ'), 'occurs')),\n",
       " (-10.86988187137653, ((329, 'הם'), 'occurs')),\n",
       " (-10.86988187137653, ((346, 'תט'), 'occurs')),\n",
       " (-10.86988187137653, ((403, 'גג'), 'occurs')),\n",
       " (-10.86988187137653, ((464, 'חג'), 'occurs')),\n",
       " (-10.86988187137653, ((485, 'גס'), 'occurs')),\n",
       " (-10.86988187137653, ((501, 'עם'), 'occurs')),\n",
       " (-10.86988187137653, ((509, 'חץ'), 'occurs')),\n",
       " (-10.86988187137653, ((525, 'עף'), 'occurs')),\n",
       " (-10.86988187137653, ((530, 'תך'), 'occurs'))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_coefficients = list(zip(clf.coef_[0], feature_vector_description))\n",
    "sorted(list(model_coefficients), reverse=False, key=lambda tuple: tuple[0])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:59:12.578931Z",
     "start_time": "2019-02-21T04:59:12.510810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('הלבשה', 0),\n",
       " ('התלבשו', 1),\n",
       " ('התלבשה', 1),\n",
       " ('הלבישה', 0),\n",
       " ('התלבש', 1),\n",
       " ('לבש', 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['הלבשה', 'התלבשו', 'התלבשה', 'הלבישה', 'התלבש', 'לבש']\n",
    "list(zip(words, (clf.predict(list(map(vectorize, words))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:59:13.614937Z",
     "start_time": "2019-02-21T04:59:12.580959Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = X_test_pos + X_test_neg\n",
    "y_test = y_test_pos + y_test_neg\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:59:13.631472Z",
     "start_time": "2019-02-21T04:59:13.616443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8606620477290223"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:59:13.703011Z",
     "start_time": "2019-02-21T04:59:13.634352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.90      0.92      5515\n",
      "          1       0.53      0.63      0.58       980\n",
      "\n",
      "avg / total       0.87      0.86      0.87      6495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:59:13.779464Z",
     "start_time": "2019-02-21T04:59:13.705101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4973,  542],\n",
       "       [ 363,  617]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:59:13.819096Z",
     "start_time": "2019-02-21T04:59:13.781663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8606620477290223"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T01:37:27.972181Z",
     "start_time": "2019-02-16T01:37:27.965686Z"
    }
   },
   "source": [
    "## _3 pts_ | Question 1 \n",
    "to understand how badly a model is performing, it is good to come up with a naive baseline, unless there is a benchmark result to compare to. assume you have no benchmark to compare to, and you hence wish to have a baseline.***suggest and calculate a reasonable even if naive, baseline over the test set***. hint: think of the class distribution in the data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _2 pts_ | Question 2 \n",
    "what can you say about the performance obtained here, according to your baseline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _3 pts_ | Question 3\n",
    "in light of the above, suggest and implement an adjusted accuracy metric, that would better account for the class imbalance inherent in our data. class imbalance is defined as a case where the distribution of classes in the data is far from being uniform.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _8 pts_ | Question 4\n",
    "suggest better features based on properties of the Hebrew language. which language feature comes into aid in that? (*hint: think of features abscent e.g. in English*). implement the features and provide a notebook with your implementation and the resulting performance report showing its contribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _4 pts_ | Question 5\n",
    "now alternatively suggest and apply features specifically for English. Provide a notebook with your implementation classifying over the English data of https://github.com/UniversalDependencies/UD_English-EWT, including a performance report.\n",
    "\n",
    "*use the following code cell to download and use the chosen version of this data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T04:59:13.907134Z",
     "start_time": "2019-02-21T04:59:13.821296Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "!git clone https://github.com/UniversalDependencies/UD_English-EWT\n",
    "!cd UD_English-EWT && git checkout 7be629932192bf1ceb35081fb29b8ecb0bd6d767"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _30 pts_ | Question 6 \n",
    "_In this question you will implement a classifier that takes account of the context of a word_. This means, you will no longer classify a word, context-less, but rather, you will transition to classifying words as part of the sentence they appear in. It will open the way for bringing additional features into play in your model, and very hopefully, lead to substantially improved classification performance.\n",
    "\n",
    "+ You may reuse the code of this notebook in any way, or write from scratch.\n",
    "\n",
    "+ You will be graded based upon:\n",
    "\n",
    "   + dilligence and creativity in adding reasonable features\n",
    "   + score on the test set, obtained when run for grading\n",
    "   + reproducibility: does your submitted solution notebook actually run when downloaded for grading\n",
    "   + cleanly structured, mildly self-explanatory or documented code\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _20 pts_ | Question 7\n",
    "Implement the _Multinomial Naive Bayes_ algorithm itself from scratch. Establish the same performances as obtained with the ready-made Multinomial Naive Bayes algorithm that you have used so far.\n",
    "\n",
    "What to submit for this?\n",
    "+ a working notebook using your own implemented Naive Bayes classifier rather than the sklearn one, per each of the programming assignments you have already implemented above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T06:13:49.246793Z",
     "start_time": "2019-02-17T06:13:49.240278Z"
    }
   },
   "source": [
    "## _20 pts_ | Question 8\n",
    "Implement the _logistic regression_ algorithm itself from scratch. Establish the same performances as obtained with the ready-made logistic regression algorithm that you have used so far.\n",
    "\n",
    "What to submit for this?\n",
    "+ a working notebook using your own implemented logistic regression algorithm rather than the sklearn one, per each of the programming assignments you have already implemented above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _10 pts_ | Question 9\n",
    "*Manual domain adaptation.* \n",
    "<br>\n",
    "1. obtain an unrelated Hebrew dataset; \n",
    "\n",
    "    + this can be a liberated copy of your gmail inbox ([google data takeout](https://takeout.google.com/settings/takeout))\n",
    "    + a whatsapp data export\n",
    "    + public hebrew tweets\n",
    "    + a hebrew wikipedia dump\n",
    "\n",
    "\n",
    "2. Use your best accomplished model over some subset of that data.\n",
    "\n",
    "<br><br>\n",
    "What to submit for this?\n",
    "1. Provide a simple report of its success rate over that data (comparing to the original results)\n",
    "2. Try to analyze towards a qualitative description of the difference in the performance; Submit your analysis.\n",
    "+ _15 pts bonus:_ modify the training data to improve performance over your data. submit your modified training data here as well.\n",
    "\n",
    "<span style=\"color:gray\">what not to include in your submission?</span>\n",
    "+ <span style=\"color:gray\">You may not include in your new data, any data explicitly or implicitly disclosing the identity or personal information of any person/s. Anonymize any non-public data that you use as necessary to comply with this requirement.</span>\n",
    "+ <span style=\"color:gray\">You may not include any proprietary or confidential data in your new data.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange\">Submission Notes</span>\n",
    "\n",
    "+ <span style=\"color:red\">Note that non-reproducible results will be ignored.</span>\n",
    "+ <span style=\"color:red\">Any submission that does not actually run (halts with an error) will immediately deduce 5 pts. Any re-submission that does not actually run (halts with an error) will deduce additional 5 pts each. So make sure to verify that your code submission runs before submitting it.</span>\n",
    "+ <span style=\"color:gray\">if any of your code should take more than 10 minutes to run, require more than 16GB of memory, or happen to rely on a GPU, please provide a notifcation in advance.\n",
    "\n",
    "The way to avoid this troubles, is to bundle your solution into a compressed zip archive, unzip it to an empty folder, and verify it is running from scratch from there.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
