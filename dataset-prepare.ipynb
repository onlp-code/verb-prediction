{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# HTB Dataset Pre-processing for homework tasks ğŸ”¨\n",
    "for now, it only retrieves and tokenizes the sentences from the HTB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "This notebook transforms the HTB dataset from https://github.com/UniversalDependencies/UD_Hebrew-HTB, into what you need for the verb-prediction assignment. You may equally copy the code into `.py` file and run it directly outside the jupyter environment here (in a command prompt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T08:05:18.965894Z",
     "start_time": "2019-02-11T08:05:18.957234Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Downloading the right version of the HTB\n",
    "To future-proof, we standardize on a specific version of the HTB. <br>Those with a keen eye will notice we use here the quick-and-dirty âš¡ way of launching OS commands from directly within the notebook. <br>âš™ Anyway, make sure you have git installed and working on your OS before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T16:32:59.121426Z",
     "start_time": "2019-02-11T16:32:54.936117Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'UD_Hebrew-HTB'...\n",
      "remote: Enumerating objects: 22, done.\u001b[K\n",
      "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
      "remote: Total 191 (delta 9), reused 15 (delta 5), pack-reused 169\u001b[K\n",
      "Receiving objects: 100% (191/191), 8.93 MiB | 3.17 MiB/s, done.\n",
      "Resolving deltas: 100% (106/106), done.\n",
      "Checking connectivity... done.\n",
      "Note: checking out '82591c955e86222e32531336ff23e36c220b5846'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by performing another checkout.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -b with the checkout command again. Example:\n",
      "\n",
      "  git checkout -b <new-branch-name>\n",
      "\n",
      "HEAD is now at 82591c9... Updated treebank evaluation.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/UniversalDependencies/UD_Hebrew-HTB\n",
    "!cd UD_Hebrew-HTB && git checkout 82591c955e86222e32531336ff23e36c220b5846"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T08:15:50.352238Z",
     "start_time": "2019-02-11T08:15:50.345381Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "the code cell above is not [idempotent](https://www.wikiwand.com/en/Idempotence) because it fails when run more than once ğŸ’¥ it's oftentimes good practice to have notebooks completely idempotent. What would be two entirely differnt ways of making that cell idempotent? ğŸ’¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T16:32:59.277169Z",
     "start_time": "2019-02-11T16:32:59.125076Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5241 sentences read\n"
     ]
    }
   ],
   "source": [
    "train_set = 'UD_Hebrew-HTB/he_htb-ud-train.conllu'\n",
    "\n",
    "sentences = []\n",
    "with open(train_set, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('# text = '):\n",
    "            sentences.append(line[len('# text = '):])\n",
    "            \n",
    "print('{} sentences read'.format(len(sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T08:31:19.991771Z",
     "start_time": "2019-02-11T08:31:19.987588Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Observing what we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T16:32:59.293470Z",
     "start_time": "2019-02-11T16:32:59.279822Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['×”×•× ×§×¨× ×“×¨×•×¨ ×œ×™×¦×¨×™ ×”× ×§××” ×”×›×™ ×›××•×¡×™×.\\n',\n",
       " '× ×¢×©×•×ª ×©× ×¢×•×“ ×××•×ª ×¡×“×¨×•×ª ×©×”×Ÿ ×™×¨×•×“×•×ª ×‘×™×•×ª×¨, ×•×œ×›×Ÿ ×”×”×©×•×•××” ××™× ×” ×”×•×’× ×ª\".\\n',\n",
       " '×”×¨×™ ×›×›×œ×•×ª ×”×›×œ ×”××œ×˜ ×”×™×” ×¡×§× ×“×™× ×•×•×™.\\n',\n",
       " '×”×”× ×”×œ×” ××£ ×“× ×” ×‘×”×›× ×ª ××¡××š ×‘×§×©×” ×œ×¡×™×•×¢ ×—×™×¨×•× ××”×××©×œ×”.\\n',\n",
       " '×•×”× ×”, ×××– ×¤×¨×¥ ××” ×©×¤×¨×¥ ×‘××¤×¨×¥, ××™×Ÿ ×©×‘×•×¢ ×©×‘×• ×œ× ×§×•×©×¨×™× ×”×¦×•×¤×¨×™× ×‘××§×•× ×›×œ×©×”×• ×§×©×¨ ××¤×œ ×œ×§×¦×¨ ××ª ×—×™×™ ×”×ª×•×©×‘×™×.\\n',\n",
       " '×œ× ××—×ª, ×›×“×™ ×œ× ×œ×¡×›×Ÿ ××ª ×¡×™×›×•×™×™ ×”× ×™×©×•××™× ×©×œ ×”×‘× ×•×ª, ××¢×“×™×¤×™× ×”××‘×•×ª ××™×Ÿ ××•×¨××œ×™ ×•×× ××œ×™.\\n',\n",
       " '×”×¢×™×ª×•×Ÿ ××•×¡×¨, ××¤×™ ×¢×“×™× ×‘××—×œ×§×ª ×”×¢×‘×•×“×•×ª ×”××™×•×—×“×•×ª, ×›×™ ×-× ×•×¡×™×™×¨ ×”×’×™×‘ ×‘×–×¢× ×›×©×©××¢ ×¢×œ ×”×”×¢×‘×¨×”.\\n',\n",
       " '× ××¡×¨ ×¢×œ ×¨×™××•×Ÿ ×’×– ×©× ×™×¤×¥ ×©××©×ª×” ×©×œ ××›×•× ×™×ª.\\n',\n",
       " '×”×’× ×¨×œ × ×•×¨××Ÿ ×©×•×•×¨×¦×§×•×£, ××¤×§×“ ×”×’×™×™×¡×•×ª ×”×××¨×™×§××™×™× ×”× ×¢×¨×›×™× ××•×œ ×¢×™×¨××§, ××¢×¨×™×š ×›×™ \"×”×›×•×—×•×ª ×©×‘×¤×™×§×•×“×• ××¡×•×’×œ×™× ×œ××—×•×§ ××ª ×¢×™×¨××§ ××Ÿ ×”××¤×”\".\\n',\n",
       " '×‘×’×™×œ 61 ×¢×–×‘ ×¨×©××™×ª ××ª ×‘×™×ª ×”×¡×¤×¨ ×•×”×—×œ ×œ×”×ª×¤×¨× ×¡ ×›× ×”×’ ××•× ×™×ª, ×—×•×˜×‘ ×¢×¦×™×, ××©×™×˜ ×¨×¤×¡×•×“×” ×‘× ×”×¨ ×•× ×”×’ ××©××™×ª.\\n',\n",
       " '×× ×™ ×’× ××¡×›×™× ×‘×”×—×œ×˜ ×©×œ×¦×“ ×”×¢× ×™×™×Ÿ ×”×œ××•××™ ×¦×¨×™×š ×œ×©×™× ×“×’×© ×—×–×§ ×™×•×ª×¨ ×¢×œ ×”×œ×§×— ×”×”×•×× ×™×¡×˜×™: ×“×™×›×•×™ ×”×’×–×¢× ×•×ª, ×‘×™×¦×•×¨ ×”×“××•×§×¨×˜×™×” ×•×›×•.\\n',\n",
       " '×××—×¨ ×©×‘×›×œ ×“×œ×ª ×™×© 21 ×—×™×‘×•×¨×™×, ×‘×¨×•×¨ ×©×œ××™×›×•×ª ×”×¢×‘×•×“×”, ×›××• ×’× ×œ×˜×™×‘ ×”×“×‘×§×™×, ×™×© ×—×œ×§ ××›×¨×™×¢ ×‘×˜×™×‘ ×”××˜×‘×— ×©×¨×•×›×©×™×.\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(sentences, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Cleaning\n",
    "\n",
    "We don't really need the newline characters this time around, so we'll drop them. <br>but do all sentences in our data end with a newline? are newline characters used also within sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T16:32:59.364053Z",
     "start_time": "2019-02-11T16:32:59.295441Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    if not sentence.endswith('\\n'):\n",
    "        print(sentence)\n",
    "        \n",
    "for sentence in sentences:\n",
    "    if sentence.index('\\n') < len(sentence)-1:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "okay, so we remove the end of line chars.\n",
    "<br>we do not remove period characters, because they are not the only end of sentence character allowed in canonical language (which ones are allowed?). read on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T16:32:59.446514Z",
     "start_time": "2019-02-11T16:32:59.365907Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "sentences = [sentence[:-1] for sentence in sentences] # this pythonic syntax is called list comprehensions, BTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T16:32:59.514437Z",
     "start_time": "2019-02-11T16:32:59.449078Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['××¢×œ ×œ××™×˜×ª×• ×ª×œ×•×™ ×ª×¦×œ×•× ×§×˜×Ÿ ×©×œ ×”××¤×™×¤×™×•×¨.',\n",
       " '×‘××•×¤×Ÿ ×¤×¨×“×•×§×¡×œ×™, × ×•×¦×¨ ××¦×‘ ×©×‘×• ××¨×”\"×‘ ××ª×—××§×ª ××œ×§×™×™× ×“×™××œ×•×’ ×‘×¨××” ×”××¡×˜×¨××˜×’×™×ª ×“×•×•×§× ×¢× ×”××“×™× ×” ×”×™×—×™×“×” ×‘××–×¨×— ×”×ª×™×›×•×Ÿ ×¢××” ×™×© ×œ×” ×”×¡×›× ×—×ª×•× ×œ×©×™×ª×•×£ ×¤×¢×•×œ×” ××¡×˜×¨××˜×’×™.',\n",
       " '×ª××™×›×ª ×’×× ×“×™ ××‘×˜×™×—×” ×œ×©×§××¨ 280 ×§×•×œ×•×ª ×‘×¤×¨×œ×× ×˜.',\n",
       " '×‘×©×‘×™×œ ×”×™×©×™×‘×” ×”×™×” ×™×•×ª×¨ ×§×œ ×œ×’×™×™×¡ ×›×¡×¤×™×.',\n",
       " '×”×‘× ×•×ª ×‘×¢×™×§×¨ ×¡×•×‘×œ×•×ª ×\"×¦×™×¤×™×•×ª ×¡×•×ª×¨×•×ª\" ×©×œ ×”×•×¨×™×”×Ÿ, ××•××¨ ×”×™×•×¢×¥ ×”×¤×¡×™×›×•×œ×•×’×™ ×‘×‘×ª×™-×¡×¤×¨ ×‘×‘×¨×œ×™×Ÿ, ×’×•××”×•×¨ ×˜×§×‘××¡×¨×Ÿ: ×”××¡×¨ ×”×•× \"××¡×•×¨ ×œ×š ×œ×‘×œ×•×˜ ××‘×œ ××ª ×—×™×™×‘×ª ×œ×”×™×©××¨ ×˜×•×¨×§×™×™×”\" (×œ×‘×œ×•×˜ ×‘×¡×‘×™×‘×” ×•×œ×¢×•×¨×¨ ××ª ×œ×¢×’×” ×¢×œ-×™×“×™ ×‘×’×“×™× ×”× ×—×©×‘×™× ×¦× ×•×¢×™× ×•××˜×¤×—×ª ×¨××©), ×¡×ª×™×¨×” ×©××™× ×” × ×™×ª× ×ª ×œ×™×™×©×•×‘.',\n",
       " '×”×•× ×”××©×™× ××ª ××©×¨×“ ×”××•×¦×¨ ×‘×¢×™×›×•×‘ ×”×¢×‘×¨×ª 80 ××™×œ×™×•×Ÿ ×©\"×— ×œ××§×•×¨×•×ª ×›×¡×•×‘×¡×™×“×™×” ×œ×©× ×ª 90 ×•×›×ª×©×œ×•× ×¢×œ ××¤×¢×œ×™ ××™× ×©×”×—×‘×¨×” ×”×§×™××” ×”×©× ×”.',\n",
       " '×‘××•×¤×™×• ×”×™×” ×›×”× × ××™×© ××œ×™× ×•××ª×¤×¨×¥.',\n",
       " '×”×™× × ×¨×¦×—×” ×‘×™×“×™ ××—×™×”.',\n",
       " '××›×‘×™ ×¨××ª ×’×Ÿ ×©××˜ × ×™×¦×—×•×Ÿ ××—×¨×™ ×©×”×•×‘×™×œ ×‘××¨×‘×™×ª ×“×§×•×ª ×”××©×—×§.',\n",
       " '×”××©×œ×—×ª ×›×•×œ×œ×ª ×©×œ×•×©×” ××©×§×•×œ××™×.',\n",
       " '×”×ª××•× ×•×ª ×©×©×© ××”×Ÿ ××•×¤×™×¢×•×ª ×‘×¡×¤×¨ ××’×¨×•×ª ××ª ×”×–×™×•×ª×™×• ×”××™× ×™×•×ª ×©×œ ×“×•×Ÿ ×¨×™×’×•×‘×¨×˜×•.',\n",
       " '×”× ××©× ×”×ª×§×©×¨ ×‘××¨×¥ ×¢× ×¢×•×œ×” ×××ª×™×•×¤×™×”, ×’×¨×•×©×” ×•×× ×œ×©× ×™ ×™×œ×“×™×.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(sentences, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "So rather than remove periods and question/exclamation marks, we make them a token in their own right, wherever encountered, much like the treatment we give other punctuation characters when tokenizing text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Tokenization\n",
    "Tokenizing is not the most exciting nor a trivial task; some characters just carry ambiguity, for example:\n",
    "\n",
    "+ the dot character (`.`) has different uses:\n",
    "    + the dog barked.\n",
    "    + 0.33\n",
    "    + David C.\n",
    "    + Sept. 2000\n",
    "    + M.D.\n",
    "    + Mr.\n",
    "    + Mrs.\n",
    "    + SKU 3343.22.CE\n",
    "    <br><br>\n",
    "+ a hebrew quote character (`\"`) has different uses:\n",
    "    + \"×”×•× ×××¨ \"×œ× ×”×‘× ×ª×™\n",
    "    + ×“\"×¨ ×©×§×©×•×§×”\n",
    "    + \"×”×™× ×××¨×” ×©\"×œ×\n",
    "    <br><br>\n",
    "\n",
    "+ this also holds for other and additional characters â€• depending on the language, language register, and even on written locale conventions mainly concerning the writing of numbers and dates.\n",
    "\n",
    "<br>We will not discuss tokenization yet, but rather use a ready made tokenization function pre-supplied. You may browse it to see what's involved, and generally, other approaches for tokenization abound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T16:33:00.623734Z",
     "start_time": "2019-02-11T16:32:59.517648Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['×‘×©×‘×•×¢×™×™×',\n",
       "  '×”××—×¨×•× ×™×',\n",
       "  '×›×‘×¨',\n",
       "  '×¨××™×™×Ÿ',\n",
       "  '×©×¨',\n",
       "  '×”××©×˜×¨×”',\n",
       "  '×›×¢×©×¨×”',\n",
       "  '×§×¦×™× ×™',\n",
       "  '××©×˜×¨×”',\n",
       "  '×× ×•×¡×™×',\n",
       "  '×•×¦×¢×™×¨×™×',\n",
       "  '×™×—×¡×™×ª',\n",
       "  '×‘×“×¨×’×ª',\n",
       "  '× ×™×¦×‘',\n",
       "  '××©× ×”',\n",
       "  ',',\n",
       "  '××§×¨×‘',\n",
       "  '×©×“×¨×ª',\n",
       "  '×”×‘×™× ×™×™×',\n",
       "  '×©×œ',\n",
       "  '×¤×™×§×•×“',\n",
       "  '×”××©×˜×¨×”',\n",
       "  ',',\n",
       "  '×›××•×¢××“×™×',\n",
       "  '×œ××™×™×©',\n",
       "  '××ª',\n",
       "  '×™×—×™×“×ª',\n",
       "  '×”××˜×”',\n",
       "  '×”××§×¦×•×¢×™×ª',\n",
       "  '×©×œ×•',\n",
       "  '.'],\n",
       " ['×¨×§',\n",
       "  '××—×¨×™',\n",
       "  '×©×¨××™×ª×™',\n",
       "  '××ª',\n",
       "  '×”×¡×¨×˜',\n",
       "  '×¢× ×§',\n",
       "  '×¢×',\n",
       "  '×’×™×™××¡',\n",
       "  '×“×™×Ÿ',\n",
       "  '×”×‘× ×ª×™',\n",
       "  '×××™×¤×”',\n",
       "  '×××¨×§',\n",
       "  '×œ×§×—',\n",
       "  '××ª',\n",
       "  '×”××× ×™×™×¨×•×ª',\n",
       "  '×•××ª',\n",
       "  '×”××™××™×§×”',\n",
       "  '×©×œ×•',\n",
       "  '.'],\n",
       " ['×œ×ª× ×•×¢×ª',\n",
       "  '×”××—××”',\n",
       "  '×”×¦×˜×¨×¤×•',\n",
       "  '×’×',\n",
       "  '×”××™×’×•×“×™×',\n",
       "  '×”××§×¦×•×¢×™×™×',\n",
       "  '×©×œ',\n",
       "  '×”×˜×œ×•×•×™×–×™×”',\n",
       "  '.'],\n",
       " ['×‘××§×‘×™×œ',\n",
       "  ',',\n",
       "  '×¤× ×•',\n",
       "  '×›××”',\n",
       "  '××™×¦×¨× ×™',\n",
       "  '×”×¨×”×™×˜×™×',\n",
       "  '×œ××©×¨×“',\n",
       "  '×”×ª×¢×©×™×™×”',\n",
       "  '×•×”××¡×—×¨',\n",
       "  '×‘×“×¨×™×©×”',\n",
       "  '×©×œ×',\n",
       "  '×œ×”×›×™×Ÿ',\n",
       "  '×ª×§×Ÿ',\n",
       "  '×›×–×”',\n",
       "  '.'],\n",
       " ['×¤×¨×•×™×§×˜×™×',\n",
       "  '×—×“×©×™×',\n",
       "  '×‘××—×§×¨',\n",
       "  '×•×¤×™×ª×•×—',\n",
       "  '×‘×”×™×§×£',\n",
       "  '×›×•×œ×œ',\n",
       "  '×©×œ',\n",
       "  '×©××•× ×”',\n",
       "  '××™×œ×™×•×Ÿ',\n",
       "  '×“×•×œ×¨',\n",
       "  ',',\n",
       "  '×”××©×•×ª×¤×™×',\n",
       "  '×œ×—×‘×¨×•×ª',\n",
       "  '×™×©×¨××œ×™×•×ª',\n",
       "  '×•×××¨×™×§××™×•×ª',\n",
       "  ',',\n",
       "  '×™×•×’×©×•',\n",
       "  '×œ××•×¢×¦×ª',\n",
       "  '×”×× ×”×œ×™×',\n",
       "  '×©×œ',\n",
       "  '×”×§×¨×Ÿ',\n",
       "  '×”×“×•-×œ××•××™×ª',\n",
       "  '×œ××•\"×£',\n",
       "  '×™×©×¨××œ-××¨×”\"×‘',\n",
       "  '×©×ª×ª×›× ×¡',\n",
       "  '×”×©×‘×•×¢',\n",
       "  '×‘×™×¨×•×©×œ×™×',\n",
       "  '.'],\n",
       " ['×œ×§×—',\n",
       "  '×–×”',\n",
       "  '×™×—×–×™×¨',\n",
       "  '××•×ª× ×•',\n",
       "  '×œ×“×¨×š',\n",
       "  '×¤×•×œ×™×˜×™×ª',\n",
       "  '× ×‘×•× ×”',\n",
       "  '×•×™×¢× ×™×§',\n",
       "  '×œ× ×•',\n",
       "  '×›×•×—',\n",
       "  '×œ×—×–×•×¨',\n",
       "  '×œ×©×œ×˜×•×Ÿ',\n",
       "  '×‘×¨×’×¢',\n",
       "  '×”××ª××™×',\n",
       "  '.'],\n",
       " ['×”××§×•×¨×•×ª',\n",
       "  '×”×¤×œ×©×ª×™× ×™×™×',\n",
       "  '×”×•×¡×™×¤×•',\n",
       "  '×›×™',\n",
       "  '×›×•×—×•×ª',\n",
       "  '×¦×”\"×œ',\n",
       "  '×¢×¦×¨×•',\n",
       "  '×¨×‘×™×',\n",
       "  '××Ÿ',\n",
       "  '×”××ª×¤×¨×¢×™×',\n",
       "  '.'],\n",
       " ['×—× ×™×›×™×•',\n",
       "  '×©×œ',\n",
       "  '××œ×™',\n",
       "  '×—×’×’',\n",
       "  '××‘×™×ª\"×¨',\n",
       "  '× ×ª× ×™×”',\n",
       "  '×”×ª××•×©×©×•',\n",
       "  '×¢×œ',\n",
       "  '×—×©×‘×•×Ÿ',\n",
       "  '×”×¢×›×•××™×',\n",
       "  '.'],\n",
       " ['××œ×”',\n",
       "  '××§×•×•×™×',\n",
       "  '×œ×—×œ×•×§×ª',\n",
       "  '×”××¨×¥',\n",
       "  '×‘×™×Ÿ',\n",
       "  '×©× ×™',\n",
       "  '×”×¢××™×',\n",
       "  '×•××œ×”',\n",
       "  '×œ×˜×¨×× ×¡×¤×¨',\n",
       "  '×©×œ',\n",
       "  '×”×¤×œ×©×ª×™× ××™×',\n",
       "  ',',\n",
       "  '××‘×œ',\n",
       "  '×ª×¨×•×¤×ª-×”×‘×™× ×™×™×',\n",
       "  '×‘×“×¨×š',\n",
       "  '×œ×¤×ª×¨×•×Ÿ',\n",
       "  '×”×©× ×•×™',\n",
       "  '×‘××—×œ×•×§×ª',\n",
       "  '××—×™×“×”',\n",
       "  '.'],\n",
       " ['×‘×‘×™×§×•×¨×•',\n",
       "  '×‘×‘×¨×™×˜× ×™×”',\n",
       "  '×¡×™×›×',\n",
       "  '×‘×™×™×§×¨',\n",
       "  '×¢×',\n",
       "  '×¨××©',\n",
       "  '×”×××©×œ×”',\n",
       "  ',',\n",
       "  '×××¨×’×¨×˜',\n",
       "  '×ª××¦×¨',\n",
       "  ',',\n",
       "  '×›×™',\n",
       "  '××•×¢×¦×ª',\n",
       "  '×”×‘×™×˜×—×•×Ÿ',\n",
       "  '×©×œ',\n",
       "  '×”××•\"×',\n",
       "  '×ª×ª×‘×§×©',\n",
       "  '×©×•×‘',\n",
       "  '×œ××©×¨',\n",
       "  '×©×™××•×©',\n",
       "  '×‘×›×•×—',\n",
       "  '×›×“×™',\n",
       "  '×œ×¤× ×•×ª',\n",
       "  '××ª',\n",
       "  '×¢×™×¨××§',\n",
       "  '××›×•×•×™×™×ª',\n",
       "  '.']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hltk.tokenization.tokenizer import tokenize\n",
    "\n",
    "tokenized = list(map(tokenize ,sentences))\n",
    "random.sample(tokenized, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidePrompt": true
   },
   "source": [
    "***Question***: What would've happened hadn't we removed the newline characters first? and could we, very alternatively, defer treating them to a later stage rather than cleaning them away first?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have possibly noticed in the foregoing, that for short sentences, jupyter may display the Hebrew text LTR rather than RTL (from left to right rather than from right to left), or just garble the order of words with regard to punctuation. Go back and check. \n",
    "\n",
    "This phenomena is due to at least two key factors:\n",
    "\n",
    "+ Any component in the application stack, the specific browser implementation or locale settings, the web page's code or front-end frameworks used, or in badly-written cases the application itself, may tweak or retrofit letter order and/or word order, as well as decide the proper horizontal alignment. \n",
    "<br>Practically, _printing one word per line_ entirely side-steps this aspect (in a cross-platform way!), at least for languages strictly characterized as keeping a horizontal writing order. <br><br>\n",
    "\n",
    "+ Additionally, [perhaps even the most standardized algorithm for handling mixed language texts](https://en.wikipedia.org/wiki/Bi-directional_text?Unicode_bidi_support), a.k.a bidirectional text, will not always work as intended, because bi-directional text can be by definition ambiguous (think, why? in what cases? we will deeply study a concept you still don't have at this stage of the course, that may help to come up with an answer). <br><br>And so, the layer of display logic in charge of multi-lingual text display, may actually garble indentation e.g. with RTL text when assuming an LTR default, as the display stack in your browser works to figure how to display your text. \n",
    "\n",
    "<br>*it is interesting to note, that in spoken text we _do not have this problem at all_, because the sounds of speech are always uttered in their natural order along the time axis, regardless of the languages involved. It is in writing, that the ordering transforms from being temporal to being gemoetric, thusly giving rise to these issues when different-directionality languages are interleaved in text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
